{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555eba4c-9275-4f23-82f9-b60d1391f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing the necessary libraries \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ee392-e672-47d1-a824-8a18c5475b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random non-crack image selection non-crack wall images:\n",
    "source_dir = '/Users/User 1/OneDrive/Desktop/Walls/Non-cracked'\n",
    "destination_dir = '/Users/User 1/OneDrive/Desktop/Non-cracked images'\n",
    "num_images = 4500\n",
    "\n",
    "def copy_random_images(source_dir, destination_dir, num_images):\n",
    "    all_files = os.listdir(source_dir)\n",
    "    image_files = [file for file in all_files \n",
    "                   if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "    selected_images = random.sample(image_files, num_images)\n",
    "    for image in selected_images:\n",
    "        source_path = os.path.join(source_dir, image)\n",
    "        destination_path = os.path.join(destination_dir, image)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "copy_random_images(source_dir, destination_dir, num_images)\n",
    "\n",
    "# Random non-crack image selection non-crack deck images:\n",
    "source_dir = '/Users/User 1/OneDrive/Desktop/Decks/Non-cracked'\n",
    "destination_dir = '/Users/User 1/OneDrive/Desktop/Non-cracked images'\n",
    "num_images = 4500\n",
    "\n",
    "def copy_random_images(source_dir, destination_dir, num_images):\n",
    "    all_files = os.listdir(source_dir)\n",
    "    image_files = [file for file in all_files \n",
    "                   if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "    selected_images = random.sample(image_files, num_images)\n",
    "    for image in selected_images:\n",
    "        source_path = os.path.join(source_dir, image)\n",
    "        destination_path = os.path.join(destination_dir, image)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "copy_random_images(source_dir, destination_dir, num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db76d2f-cc3a-4a41-b7db-0d7aa8165c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a funtion to split the images into Train, Validation and Test sets\n",
    "\n",
    "def split_data(source, train_dest, val_dest, test_dest):\n",
    "    os.makedirs(train_dest, exist_ok=True)\n",
    "    os.makedirs(val_dest, exist_ok=True)\n",
    "    os.makedirs(test_dest, exist_ok=True)\n",
    "    files = [file for file in os.listdir(source) if os.path.isfile(os.path.join(source, file))]\n",
    "    train_files, test_files = train_test_split(files, train_size=0.9, random_state=42)\n",
    "    train_files, val_files = train_test_split(train_files, train_size=0.9, random_state=42)\n",
    "     \n",
    "    def copy_files(files, source, destination):\n",
    "        for file in files:\n",
    "            shutil.copy(os.path.join(source, file), os.path.join(destination, file))\n",
    "    \n",
    "    copy_files(train_files, source, train_dest)\n",
    "    copy_files(val_files, source, val_dest)\n",
    "    copy_files(test_files, source, test_dest)\n",
    "\n",
    "# Specify the source directories for cracked and non-cracked images\n",
    "cracked_source = '/Users/User 1/OneDrive/Desktop/Cracked images'\n",
    "non_cracked_source = '/Users/User 1/OneDrive/Desktop/Non-cracked images'\n",
    "\n",
    "# Base directory to collect the image data for Train, Validation, and Test datasets\n",
    "base_dir = '/Users/User 1/OneDrive/Desktop/Base'\n",
    "\n",
    "def count_images(directory):\n",
    "    \"\"\"Counts the number of files in the directory.\"\"\"\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "# Count the images in each directory\n",
    "num_cracked_images = count_images(cracked_source)\n",
    "num_non_cracked_images = count_images(non_cracked_source)\n",
    "\n",
    "print(f\"Number of images in cracked source: {num_cracked_images}\")\n",
    "print(f\"Number of images in non-cracked source: {num_non_cracked_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ad2b0-3c2f-4501-a806-d7cadd4a89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the destination paths and splitting operation:\n",
    "\n",
    "train_cracked = os.path.join(base_dir, 'train/cracked')\n",
    "val_cracked = os.path.join(base_dir, 'validation/cracked')\n",
    "test_cracked = os.path.join(base_dir, 'test/cracked')\n",
    "train_non_cracked = os.path.join(base_dir, 'train/non cracked')\n",
    "val_non_cracked = os.path.join(base_dir, 'validation/non cracked')\n",
    "test_non_cracked = os.path.join(base_dir, 'test/non cracked')\n",
    "\n",
    "# Then execute the split for both decks and walls, such that the image is loaded into the Base directory \n",
    "split_data(cracked_source, train_cracked, val_cracked, test_cracked)\n",
    "split_data(non_cracked_source, train_non_cracked, val_non_cracked, test_non_cracked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe0aab-7b31-4430-a555-3a61e555d52c",
   "metadata": {},
   "source": [
    "**VGG16 NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393f2bd-774e-4357-8f8d-f8500df79b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/User 1/OneDrive/Desktop/Base/train'\n",
    "validation_dir = '/Users/User 1/OneDrive/Desktop/Base/validation'\n",
    "test_dir = '/Users/User 1/OneDrive/Desktop/Base/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def generator_to_dataset(generator):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.float32))\n",
    "    ).repeat()\n",
    "\n",
    "train_dataset = generator_to_dataset(train_generator)\n",
    "validation_dataset = generator_to_dataset(validation_generator)\n",
    "test_dataset = generator_to_dataset(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f699e3-7c95-4fa0-a916-79b7dbc60259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 model pre-trained on ImageNet, without top layers\n",
    "\n",
    "base_model = VGG16(weights='imagenet', \n",
    "                   include_top=False, \n",
    "                   input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "VGG16_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "VGG16_model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9),\n",
    "                    loss='binary_crossentropy', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = VGG16_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb4094-96a7-42c9-9928-96e1d9963eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the trained VGG16 model on the test set:\n",
    "test_loss, test_accuracy = VGG16_model.evaluate(test_generator)\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = VGG16_model.predict(test_generator)\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.round(predictions).astype(int).reshape(-1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa4569-d4f2-4c65-9904-6134db331c11",
   "metadata": {},
   "source": [
    "**OPTIMIZATION VGG16 (Optimizer=Adam)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f7772-1c54-48d8-871f-eee942fd10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 model pre-trained on ImageNet, without top layers\n",
    "\n",
    "base_model = VGG16(weights='imagenet', \n",
    "                   include_top=False, \n",
    "                   input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "VGG16_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "VGG16_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                    loss='binary_crossentropy', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = VGG16_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03457c19-2c5b-40d7-b3b9-3935ccfbcc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the trained VGG16 model on the test set:\n",
    "test_loss, test_accuracy = VGG16_model.evaluate(test_generator)\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = VGG16_model.predict(test_generator)\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.round(predictions).astype(int).reshape(-1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93c1be-1528-4bdb-9c8b-895f07fe9659",
   "metadata": {},
   "source": [
    "**VGG19 NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b55be0-be2c-4c52-b6f2-3baedc2358a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading VGG19 model pre-trained on ImageNet, without top layers\n",
    "\n",
    "base_model = VGG19(weights='imagenet', \n",
    "                   include_top=False, \n",
    "                   input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "VGG19_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "VGG19_model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = VGG19_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=10,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c34ddf-d835-422d-8e80-ec48de832578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the trained VGG19 model on the test set:\n",
    "\n",
    "test_loss, test_accuracy = VGG19_model.evaluate(test_generator)\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = VGG19_model.predict(test_generator)\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.round(predictions).astype(int).reshape(-1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b0dd5-9fbe-4c6f-a6a1-2c01a0ed027a",
   "metadata": {},
   "source": [
    "**OPTIMIZATION VGG19 (Optimizer=Adam)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c839e-cefe-42dc-a7d8-112b7bd06a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG19 model pre-trained on ImageNet, without top layers\n",
    "\n",
    "base_model = VGG19(weights='imagenet', \n",
    "                   include_top=False, \n",
    "                   input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "VGG19_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "VGG19_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = VGG19_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a0a8d-f05b-42c0-8200-35af564161bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the trained VGG19 model on the test set:\n",
    "\n",
    "test_loss, test_accuracy = VGG19_model.evaluate(test_generator)\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = VGG19_model.predict(test_generator)\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.round(predictions).astype(int).reshape(-1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bc15e-eaf5-4946-8057-05cf07ace075",
   "metadata": {},
   "source": [
    "**RESNET18 NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9d48f-4393-41a9-a5d4-4864c9e32a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up image loaders for the ResNet models and Image Data Transformations operation:\n",
    "\n",
    "base_dir = '/Users/s4210323/OneDrive - University of Gloucestershire/Base'\n",
    "\n",
    "data_tf = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "img_datasets = {x: datasets.ImageFolder(os.path.join(base_dir, x), data_tf[x]) for x in ['train', 'validation', 'test']}\n",
    "img_loaders = {\n",
    "    'train': DataLoader(img_datasets['train'], batch_size=32, shuffle=True, num_workers=4),\n",
    "    'validation': DataLoader(img_datasets['validation'], batch_size=32, shuffle=True, num_workers=4),\n",
    "    'test': DataLoader(img_datasets['test'], batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "ds_sizes = {x: len(img_datasets[x]) for x in ['train', 'validation', 'test']}\n",
    "class_names = img_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23ad9d-d015-4d94-a753-2d19eb998bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pretained ResNet18 model:\n",
    "\n",
    "RN18_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = RN18_model.fc.in_features\n",
    "RN18_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(RN18_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "RN18_model = RN18_model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def train_model(model, criterion, optimizer, img_loaders, ds_sizes, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in img_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping:\n",
    "            if phase == 'validation':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    trigger_times = 0\n",
    "                else:\n",
    "                    trigger_times += 1\n",
    "                    print(f'Early stopping trigger times: {trigger_times}/{patience}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!')\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "RN18_model = train_model(RN18_model, criterion, optimizer, img_loaders, ds_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c35c1-546a-48de-a7a8-ff975bce4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_test, y_pred_test = evaluate_model(RN18_model, dataloaders['test'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c60213-6c23-4b44-98d8-a6197b0a6b84",
   "metadata": {},
   "source": [
    "**OPTIMIZATION RESNET18 (Optimizer=SGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6238658-4de7-4e0a-b4f7-5eae6ff2e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pretained ResNet18 model:\n",
    "\n",
    "RN18_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = RN18_model.fc.in_features\n",
    "RN18_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(RN18_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "RN18_model = RN18_model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def train_model(model, criterion, optimizer, img_loaders, ds_sizes, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in img_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping:\n",
    "            if phase == 'validation':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    trigger_times = 0\n",
    "                else:\n",
    "                    trigger_times += 1\n",
    "                    print(f'Early stopping trigger times: {trigger_times}/{patience}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!')\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "RN18_model = train_model(RN18_model, criterion, optimizer, img_loaders, ds_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbb81e-1c7f-4aca-9faf-6b184b4d0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_test, y_pred_test = evaluate_model(RN18_model, dataloaders['test'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6a6fe-1b4b-41db-9f68-d8b216b3dae1",
   "metadata": {},
   "source": [
    "**RESNET34 NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859ce5f-cda2-46f4-81bd-d7ae52afb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pretained ResNet18 model:\n",
    "\n",
    "RN34_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = RN34_model.fc.in_features\n",
    "RN34_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(RN34_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "RN34_model = RN34_model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def train_model(model, criterion, optimizer, img_loaders, ds_sizes, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in img_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping:\n",
    "            if phase == 'validation':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    trigger_times = 0\n",
    "                else:\n",
    "                    trigger_times += 1\n",
    "                    print(f'Early stopping trigger times: {trigger_times}/{patience}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!')\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "RN34_model = train_model(RN34_model, criterion, optimizer, img_loaders, ds_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df4b73-8077-49a9-a72a-650784cebbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_test, y_pred_test = evaluate_model(RN34_model, dataloaders['test'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e2ac1-d9e0-4620-85e5-e67ffbe9a664",
   "metadata": {},
   "source": [
    "**OPTIMIZATION RESNET34 (Optimizer=SGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bf04c-a335-4102-8cdf-da863e00dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pretained ResNet18 model:\n",
    "\n",
    "RN34_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = RN34_model.fc.in_features\n",
    "RN34_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(RN34_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "RN34_model = RN34_model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def train_model(model, criterion, optimizer, img_loaders, ds_sizes, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in img_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping:\n",
    "            if phase == 'validation':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    trigger_times = 0\n",
    "                else:\n",
    "                    trigger_times += 1\n",
    "                    print(f'Early stopping trigger times: {trigger_times}/{patience}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!')\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "RN34_model = train_model(RN34_model, criterion, optimizer, img_loaders, ds_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33b6fd-3003-468c-bff5-801bce8d7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_test, y_pred_test = evaluate_model(RN34_model, dataloaders['test'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f458e-a98f-431b-8985-ca4f013a0877",
   "metadata": {},
   "source": [
    "**RESNET50 NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac1de4-0197-4ce4-8dc1-dd7e08eeaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pretained ResNet18 model:\n",
    "\n",
    "RN50_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = RN50_model.fc.in_features\n",
    "RN50_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(RN50_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "RN50_model = RN50_model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def train_model(model, criterion, optimizer, img_loaders, ds_sizes, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in img_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping:\n",
    "            if phase == 'validation':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    trigger_times = 0\n",
    "                else:\n",
    "                    trigger_times += 1\n",
    "                    print(f'Early stopping trigger times: {trigger_times}/{patience}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!')\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "RN50_model = train_model(RN50_model, criterion, optimizer, img_loaders, ds_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ba9a7-09af-4eea-b7b0-ada41a698a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_test, y_pred_test = evaluate_model(RN50_model, dataloaders['test'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc789be9-8ae2-480c-8fd2-5f7c43540a17",
   "metadata": {},
   "source": [
    "**OPTIMIZATION RESNET50 (Optimizer=SGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f98004-43b6-4c6e-ba45-35cba0a1c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pretained ResNet18 model:\n",
    "\n",
    "RN50_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = RN50_model.fc.in_features\n",
    "RN50_model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(RN50_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "RN50_model = RN50_model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def train_model(model, criterion, optimizer, img_loaders, ds_sizes, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in img_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / ds_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / ds_sizes[phase]\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping:\n",
    "            if phase == 'validation':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    trigger_times = 0\n",
    "                else:\n",
    "                    trigger_times += 1\n",
    "                    print(f'Early stopping trigger times: {trigger_times}/{patience}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!')\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "RN50_model = train_model(RN50_model, criterion, optimizer, img_loaders, ds_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e016a5a-adb9-4d87-ab3f-6e80fd99e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_test, y_pred_test = evaluate_model(RN50_model, dataloaders['test'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dafe39-aa8b-4416-86b1-25f212dc415a",
   "metadata": {},
   "source": [
    "**MOBILENET NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead9ee9-c4b4-46dd-9a5b-4edd85ed4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to the dataset\n",
    "\n",
    "train_dir = '/Users/User 1/OneDrive/Desktop/Base/train'\n",
    "validation_dir = '/Users/User 1/OneDrive/Desktop/Base/validation'\n",
    "test_dir = '/Users/User 1/OneDrive/Desktop/Base/test'\n",
    "\n",
    "# Image Data Generators (Augmentation of Train Data while Training in place)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64c26f-8cfe-42b6-a9b5-d1bc854a6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model, Training and Training history:\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "MNet_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "MNet_model.compile(optimizer=SGD(learning_rate=0.0001,momentum=0.9),\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = MNet_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38965ea9-08d1-49b5-b423-f7c0e2375c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = MNet_model.evaluate(test_generator)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_prob = MNet_model.predict(test_generator)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "print(f'Test Precision: {precision:.2f}')\n",
    "print(f'Test Recall: {recall:.2f}')\n",
    "print(f'Test F1 Score: {f1:.2f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a9255-e333-4518-8a15-91cdb2b3799d",
   "metadata": {},
   "source": [
    "**OPTIMIZATION MOBILENET (Optimizer=Adam)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe59b0-d534-48e4-ac16-dbb892486023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model, Training and Training history:\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "MNet_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "MNet_model.compile(optimizer= 'adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = MNet_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ccc0f-6d0c-46c4-b4dc-342d8d39990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = MNet_model.evaluate(test_generator)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_prob = MNet_model.predict(test_generator)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "print(f'Test Precision: {precision:.2f}')\n",
    "print(f'Test Recall: {recall:.2f}')\n",
    "print(f'Test F1 Score: {f1:.2f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eedcfc5-9bb2-483a-ac1d-26bfe31bc930",
   "metadata": {},
   "source": [
    "**EVALUATING OPTIMIZED RESNET18 MODEL ON CHELTENHAM CAPTURED IMAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0390eb-5455-44d5-bd51-6df52f024707",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/s4210323/OneDrive - University of Gloucestershire/Base'\n",
    "\n",
    "data_tf = {\n",
    "    'CHL': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "img_datasets = {x: datasets.ImageFolder(os.path.join(base_dir, x), data_tf[x]) for x in ['CHL']}\n",
    "img_loaders = {\n",
    "    'CHL': DataLoader(img_datasets['CHL'], batch_size=16, shuffle=False, num_workers=4)\n",
    "}\n",
    "ds_sizes = {x: len(img_datasets[x]) for x in ['CHL']}\n",
    "class_names = img_datasets['CHL'].classes\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "for _, label in img_datasets['CHL']:\n",
    "    class_counts[class_names[label]] += 1\n",
    "\n",
    "print(f\"Dataset sizes: {ds_sizes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(\"Class distribution:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bdc29-a135-4eaf-b5ee-1bb05e5f293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "y_true_CHL, y_pred_CHL = evaluate_model(RN18_model, dataloaders['CHL'])\n",
    "\n",
    "# performance metrics calculation:\n",
    "accuracy_test = accuracy_score(y_true_CHL, y_pred_CHL)\n",
    "precision_test = precision_score(y_true_CHL, y_pred_CHL)\n",
    "recall_test = recall_score(y_true_CHL, y_pred_CHL)\n",
    "f1_test = f1_score(y_true_CHL, y_pred_CHL)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')\n",
    "print(f'Test Precision: {precision_test:.4f}')\n",
    "print(f'Test Recall: {recall_test:.4f}')\n",
    "print(f'Test F1 Score: {f1_test:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_CHL, y_pred_CHL, target_names=['cracked', 'non-cracked']))\n",
    "\n",
    "# Confusion matrix for CHL set\n",
    "cm = confusion_matrix(y_true_CHL, y_pred_CHL)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cracked', 'non-cracked'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Cheltenham Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1071e-a1c4-47b2-923e-4f7e0f8961b6",
   "metadata": {},
   "source": [
    "**CRACK ANALYSIS ON CHELTENHAM IMAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f89db9-efe4-4894-8f60-3daece1ec8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a fucntion for crack feature extraction: \n",
    "\n",
    "def calculate_crack_features(image_path, visualize=False):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edges = cv2.Canny(gray, threshold1=30, threshold2=100)\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(edges, cmap='gray')\n",
    "        plt.title('Edge Detection')\n",
    "\n",
    "    dilated = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=1)\n",
    "    if visualize:\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(dilated, cmap='gray')\n",
    "        plt.title('Dilation')\n",
    "\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_image = cv2.drawContours(image.copy(), contours, -1, (0,255,0), 3)\n",
    "    total_area = sum(cv2.contourArea(contour) for contour in contours)\n",
    "    if visualize:\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Contours')\n",
    "\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    x, counts = np.unique(lbp.ravel(), return_counts=True)\n",
    "    hist = counts / sum(counts)\n",
    "    texture_uniformity = np.var(hist)\n",
    "    if visualize:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.imshow(lbp, cmap='gray')\n",
    "        plt.title('Local Binary Patterns')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return total_area, texture_uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d68e8-ac0c-466c-8233-bac43d38c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, visualize=False):\n",
    "    crack_features = []\n",
    "    visualized_count = 0  \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            should_visualize = visualize and visualized_count < 5\n",
    "            features = calculate_crack_features(path, visualize=should_visualize)\n",
    "            crack_features.append(features)\n",
    "            if should_visualize:\n",
    "                visualized_count += 1 \n",
    "    return crack_features\n",
    "\n",
    "def categorize_crack_sizes(crack_features):\n",
    "    categories = {'small': 0, 'medium': 0, 'large': 0}\n",
    "    for area, _ in crack_features:\n",
    "        \n",
    "        ##If the size is less than 1000, describe it as small crack, medium and large\n",
    "        if area < 1000:  \n",
    "            categories['small'] += 1\n",
    "        elif area < 1500:\n",
    "            categories['medium'] += 1\n",
    "        else:\n",
    "            categories['large'] += 1\n",
    "    return categories\n",
    "\n",
    "def plot_crack_size_distribution(categories, title):\n",
    "    sizes = list(categories.keys())\n",
    "    counts = list(categories.values())\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(sizes, counts, color=['blue', 'orange', 'green'])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Crack Size Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cea5d-5751-4f5e-837c-ab7d27811517",
   "metadata": {},
   "outputs": [],
   "source": [
    "cracked_images = '/Users/User 1/OneDrive/Desktop/Base/CHL/cracked'\n",
    "\n",
    "# Set visualize=True in process_folder call to see the visualizations for the first 5 images\n",
    "crack_features = process_folder(cracked_images, visualize=True)\n",
    "\n",
    "crack_categories = categorize_crack_sizes(crack_features)\n",
    "\n",
    "plot_crack_size_distribution(crack_categories, 'Crack Size Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce346f18-0854-4829-9c66-fef5681c08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional function for plotting the numerical distribution of crack sizes\n",
    "\n",
    "def plot_crack_size_numerical_distribution(crack_categories, title):\n",
    "    categories = ['small', 'medium', 'large']\n",
    "    counts_crack = [crack_categories[category] for category in categories]\n",
    "       \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x, counts_crack, width, label='crack')\n",
    "\n",
    "    ax.set_xlabel('Crack Size Category')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    \n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c4bb4-a6d3-4b63-92fd-249b0c7f62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize the crack sizes\n",
    "crack_features = process_folder(cracked_images)  \n",
    "\n",
    "crack_categories = categorize_crack_sizes(crack_features)\n",
    "\n",
    "# Plot the numerical distribution of crack sizes\n",
    "plot_crack_size_numerical_distribution(crack_categories,'Numerical Distribution of Crack Sizes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
